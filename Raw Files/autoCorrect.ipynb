{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textdistance in /home/jellyfish/.local/lib/python3.10/site-packages (4.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words in the text are: ['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
      "Total Unique words are 39168.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# List of all text files you want to process\n",
    "file_paths = ['Vocabulary/book.txt', 'Vocabulary/alice_in_wonderland.txt', 'Vocabulary/big.txt', 'Vocabulary/shakespeare.txt']\n",
    "words = []\n",
    "\n",
    "# Loop through each file in the file_paths list\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read all the data from the text file\n",
    "        file_name_data = f.read()\n",
    "        # Convert all the content to lowercase\n",
    "        file_name_data = file_name_data.lower()\n",
    "        # Find all the alphanumeric words\n",
    "        words += re.findall(r'\\w+', file_name_data)  # Use r'\\w+' to match entire words\n",
    "\n",
    "# This is our unique vocabulary\n",
    "V = set(words)\n",
    "print(f\"Top ten words in the text are: {words[0:10]}\")\n",
    "print(f\"Total Unique words are {len(V)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, you can see that we have made a list of words and now we will build the frequency of those words, which can be easily done by using the “counter function” in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 97681), ('of', 48374), ('and', 47095), ('to', 35397), ('in', 27415), ('a', 27312), ('that', 16693), ('he', 14776), ('it', 14270), ('was', 13572)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}  \n",
    "# count the frequency of each word in the words list\n",
    "word_freq = Counter(words)\n",
    "#most common words \n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Frequency of words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now  we have to find probabilities of occurence for each word in the corpus, which equals the Relative Frequencies of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    #convert input to lowercase\n",
    "    input_word = input_word.lower()\n",
    "    #check if the input word is correct \n",
    "    if input_word in V:\n",
    "        return('Your word seems to be correct')\n",
    "    else:\n",
    "        #calculate jaccard similarity for each word: Explained in the below markdown \n",
    "        sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        #created a df from prob dict\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        #added the similarity column into df which contains jaccard sim calculated\n",
    "        df['Similarity'] = sim\n",
    "        #first sorted the df on sim, then pron\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>difference</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>differences</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>indifference</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>different</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20870</th>\n",
       "      <td>differed</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word      Prob  Similarity\n",
       "2186     difference  0.000048    0.900000\n",
       "8377    differences  0.000011    0.818182\n",
       "5097   indifference  0.000023    0.750000\n",
       "1700      different  0.000218    0.636364\n",
       "20870      differed  0.000007    0.545455"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect('diffference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sim = [1 - (textdistance.Jaccard(qval=2).distance(v, input_word)) for v in word_freq.keys()]**\n",
    "\n",
    "1. This line calculates the Jaccard similarity between the input_word and each word in the vocabulary.\n",
    "2. The Jaccard distance is calculated using the textdistance library, with the qval=2 argument indicating that we're considering 2-grams (bigrams, or pairs of consecutive characters) when calculating the similarity.\n",
    "3. The similarity is calculated as 1 - Jaccard distance to convert the distance to a similarity score. The smaller the distance, the more similar the words are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of the Jaccard distance, using the `qval=2` argument refers to **2-grams** (or **bigrams**), which are sequences of **two consecutive characters** within a word. Here's an explanation:\n",
    "\n",
    "### What is a 2-gram (bigram)?\n",
    "- A **2-gram** (or **bigram**) is a pair of consecutive characters in a word. For example, the word `\"dog\"` would have the following bigrams:\n",
    "  - **'do'**\n",
    "  - **'og'**\n",
    "\n",
    "In the case of the textdistance library, setting `qval=2` means that the similarity between two words will be computed based on these pairs of consecutive characters (2-grams).\n",
    "\n",
    "### Jaccard Similarity and Distance:\n",
    "The **Jaccard similarity** measures how similar two sets are. It's defined as the size of the intersection of two sets divided by the size of their union. When applied to bigrams, the similarity is calculated as:\n",
    "\n",
    "\\[\n",
    "\\text{Jaccard Similarity} = \\frac{\\text{Number of common bigrams}}{\\text{Number of unique bigrams in both words}}\n",
    "\\]\n",
    "\n",
    "- **Jaccard Distance** is simply \\( 1 - \\text{Jaccard Similarity} \\).\n",
    "\n",
    "For example:\n",
    "- Let's compare the words `\"dog\"` and `\"dot\"`.\n",
    "  - The **bigrams for \"dog\"** are:\n",
    "    - 'do', 'og'\n",
    "  - The **bigrams for \"dot\"** are:\n",
    "    - 'do', 'ot'\n",
    "  \n",
    "  The common bigram between `\"dog\"` and `\"dot\"` is `'do'`, so the Jaccard similarity is:\n",
    "\n",
    "  \\[\n",
    "  \\text{Jaccard Similarity} = \\frac{1}{3} = 0.33\n",
    "  \\]\n",
    "  The total number of unique bigrams is 3 ('do', 'og', 'ot'). Therefore, the Jaccard distance is:\n",
    "\n",
    "  \\[\n",
    "  \\text{Jaccard Distance} = 1 - 0.33 = 0.67\n",
    "  \\]\n",
    "\n",
    "### Why use 2-grams?\n",
    "- Using **2-grams (bigrams)** helps capture more specific information about the structure of words, especially for detecting typos or similar words.\n",
    "- For example, the words `\"dog\"` and `\"dot\"` are similar due to their common 2-gram `'do'`, even though the last characters differ.\n",
    "\n",
    "### Summary:\n",
    "- **qval=2** in the `textdistance` library means that the function will compute the similarity between words based on **pairs of consecutive characters** (2-grams).\n",
    "- This method helps to find words that are similar in terms of character sequence, even if they have small spelling differences, which is useful for autocorrection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
